{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of First_Submission.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD4nTIrIPwBL"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pSt7iNPwUoV"
      },
      "source": [
        "**Importing Necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4peDc5HvnoY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd04636-db6a-4fb5-9009-cf0172325ca7"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection\n",
        "\n",
        "import warnings\n",
        "\n",
        "nltk.download('stopwords')\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTiJQqNON60d"
      },
      "source": [
        "**Importing data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xussBHLwSm-",
        "outputId": "e41bff5b-d0b1-402f-8b67-c1324482962f"
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "print(train.shape, test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(44100, 4) (18900, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2H-f6JuOBXR"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NonD7YoZwbSh"
      },
      "source": [
        "**Text Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-Dek_RdwjxQ"
      },
      "source": [
        "def clean_text(text):\n",
        "  text = text.lower()                                        # convert text to lower\n",
        "  text = re.sub(r'<.*?>', '', text)                          # remove html tags\n",
        "  text = re.sub(r'(https?:\\/\\/|www\\.)\\S+', '', text)         # remove urls\n",
        "  text = re.sub(r'@\\S+', '', text)                           # remove '@'\n",
        "  text = re.sub(r'[\\[\\]\\(\\)]', '', text)                     # remove brackets\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsc7AOTaA69D"
      },
      "source": [
        "def text_preprocessing(text):\n",
        "\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')                       # Using RegexTokenizer\n",
        "  text = clean_text(text)                                   # clean text \n",
        "  text = tokenizer.tokenize(text)                           # Tokenize sentences\n",
        "  # text = [t for t in text if t not in stopwords.words('english')]\n",
        "  text = ' '.join(text)                                     \n",
        "\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "BVLK82P5ByDu",
        "outputId": "e11f47f1-bdee-428e-d400-17369dcb6449"
      },
      "source": [
        "train['Review'] = train['Review'].apply(lambda x: text_preprocessing(x))\n",
        "test['Review'] = test['Review'].apply(lambda x: text_preprocessing(x))\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>author</th>\n",
              "      <th>Review</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39467</td>\n",
              "      <td>rayinstirling</td>\n",
              "      <td>today i m working on my quot quirky q quot cue...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30154</td>\n",
              "      <td>DirtyRose17</td>\n",
              "      <td>dont ya know people love the human society</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16767</td>\n",
              "      <td>yoliemichelle</td>\n",
              "      <td>ughhh rejected from the 09 mediation program s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9334</td>\n",
              "      <td>jayamelwani</td>\n",
              "      <td>im so jealous i want an octo drive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>61178</td>\n",
              "      <td>aliisanoun</td>\n",
              "      <td>i remember all the hype around this movie when...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      ID  ... Sentiment\n",
              "0  39467  ...         2\n",
              "1  30154  ...         1\n",
              "2  16767  ...         0\n",
              "3   9334  ...         0\n",
              "4  61178  ...         0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TOfEE3OF8n1"
      },
      "source": [
        "**Bag-of-words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYl3zSieF-wx"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "count_vectorizer = CountVectorizer()\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "train_cv = count_vectorizer.fit_transform(train['Review'])\n",
        "test_cv = count_vectorizer.transform(test['Review'])\n",
        "\n",
        "train_tfidf = tfidf_vectorizer.fit_transform(train['Review'])\n",
        "test_tfidf = tfidf_vectorizer.transform(test['Review'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdR4ygCfHcd5"
      },
      "source": [
        "**Training model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PodchNNsHxgu",
        "outputId": "c94df37a-e160-4235-ed53-1868254598a9"
      },
      "source": [
        "# Count-Vectorized data\n",
        "clf1 = LogisticRegression(max_iter=500)\n",
        "scores = model_selection.cross_val_score(clf1, train_cv, train[\"Sentiment\"], cv=5, scoring=\"neg_log_loss\")\n",
        "scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.8827589 , -0.85888143, -0.86283002, -0.88487643, -0.89656309])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvBgcs16ouJb",
        "outputId": "9ad4dcb9-6eb5-487e-d8e6-7aedbdaae64d"
      },
      "source": [
        "# Tfidf-Vectorized data\n",
        "clf2 = LogisticRegression(max_iter=500)\n",
        "scores = model_selection.cross_val_score(clf2, train_tfidf, train[\"Sentiment\"], cv=5, scoring=\"neg_log_loss\")\n",
        "scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.71870535, -0.70465121, -0.70489987, -0.72135558, -0.71414712])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4zKaFCeNroB",
        "outputId": "941aa7c5-6174-4cb5-dbfe-6695ead77b81"
      },
      "source": [
        "# Tfidf-vectorized data gave better result. Now training on the whole dataset before inference\n",
        "clf2.fit(train_tfidf, train[\"Sentiment\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD6S3ewtO9JL"
      },
      "source": [
        "**Creating submission file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "gWDMXwiASkbF",
        "outputId": "cb7659c2-e196-4153-b700-33fb0e0a278f"
      },
      "source": [
        "preds = clf2.predict_proba(test_tfidf)\n",
        "df2 = pd.DataFrame(preds).rename(columns = {0:'Negative_0', 1:'Neutral_1', 2:'Positive_2'})\n",
        "df2.to_csv('my_submission_file.csv', index=False)\n",
        "pd.read_csv('my_submission_file.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Negative_0</th>\n",
              "      <th>Neutral_1</th>\n",
              "      <th>Positive_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.179506</td>\n",
              "      <td>0.091303</td>\n",
              "      <td>0.729191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.659003</td>\n",
              "      <td>0.166853</td>\n",
              "      <td>0.174144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.969375</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>0.030515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.529993</td>\n",
              "      <td>0.101162</td>\n",
              "      <td>0.368845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.338943</td>\n",
              "      <td>0.344546</td>\n",
              "      <td>0.316511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18895</th>\n",
              "      <td>0.423907</td>\n",
              "      <td>0.020628</td>\n",
              "      <td>0.555465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18896</th>\n",
              "      <td>0.003974</td>\n",
              "      <td>0.010613</td>\n",
              "      <td>0.985412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18897</th>\n",
              "      <td>0.693031</td>\n",
              "      <td>0.178188</td>\n",
              "      <td>0.128781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18898</th>\n",
              "      <td>0.628450</td>\n",
              "      <td>0.187763</td>\n",
              "      <td>0.183787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18899</th>\n",
              "      <td>0.424254</td>\n",
              "      <td>0.202437</td>\n",
              "      <td>0.373309</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18900 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Negative_0  Neutral_1  Positive_2\n",
              "0        0.179506   0.091303    0.729191\n",
              "1        0.659003   0.166853    0.174144\n",
              "2        0.969375   0.000110    0.030515\n",
              "3        0.529993   0.101162    0.368845\n",
              "4        0.338943   0.344546    0.316511\n",
              "...           ...        ...         ...\n",
              "18895    0.423907   0.020628    0.555465\n",
              "18896    0.003974   0.010613    0.985412\n",
              "18897    0.693031   0.178188    0.128781\n",
              "18898    0.628450   0.187763    0.183787\n",
              "18899    0.424254   0.202437    0.373309\n",
              "\n",
              "[18900 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkuBJfvg_Mk9"
      },
      "source": [
        "_______"
      ]
    }
  ]
}